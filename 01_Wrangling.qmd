---
title: "01_Wrangling"
format: html
editor: visual
---

```{r}

library(tidyverse)

```

```{r Paint_combinations, eval = FALSE}

# first chunk is to make unique paint combinations for the bees

# from Richardson et al. (2021) - https://doi.org/10.1038/s42003-021-02048-7

## This programs produces the largest possible set of colour-location combinations with a maximum given number of overlapping spots (max_common_spots, input by the user in variable max_common_spots)
## The set of colour-location combinations produced is sorted in increasing order of overlap between combinations
## Thus starting from the top of the list will always lead to the optimal set (i.e. the set minimising overlap between combinations) regardless of the number of combinations desired
## The code can be adjusted for any number of colours (variable 'colour_list') and any number of paint locations (variable 'locations')
## (Note that the processing time will scale exponentially with the number of colours and number of locations because of the increasing number of possible combinations)
## The program requires the installation of R libraries 'gtools' and 'Rcpp' and calls the associated cpp function "combination_overlap.cpp", which must be in the same folder as this program

# rm(list=ls())
# 
# library(gtools)
# library(Rcpp)
# Sys.setenv("PKG_CXXFLAGS"="-std=c++11")
# sourceCpp('/Users/faith/Desktop/U Ottawa/PhD Chapter 3/sweat_bee_ecology/Extra/Paint_ID_combination_overlap.cpp')
# 
# 
# 
# ## 1. Define Parameters 
# 
# # list of colours
# colour_list <- c("W", "G", "B", "O", "P") # list of 
# # locations on bee
# locations <- c("Top_L","Top_R","Bottom")
# # max number of identical spot combinations
# max_common_spots <- 2                                        
# # number of random trials to obtain best list. Higher = better chance of obtaining longest possible list buit longer processing time
# nb_rand <- 150
# 
# 
# ## 2. Generate all possible colour combinations, for Nb_colours colours & Nb_locations 
# 
# all_combs <- data.frame(permutations(n=length(colour_list) ,r=length(locations),v=colour_list,repeats.allowed=T), stringsAsFactors = F) ; colnames(all_combs) <- c("Top_L","Top_R","Bottom")
# 
# ## 3. Generate edge list: Nb of location-colours attributes that are identical between each pair of combinations 
# 
# all_comb_list <- list()
# for (col_idx in 1:length(locations)){
#   all_comb_list[[col_idx]] <- as.numeric(match(all_combs[,col_idx],colour_list))
# }
# edge_list <- define_edge_list(all_comb_list, length(locations), choose(nrow(all_combs),2))
# 
# ## 4. Using 1000 randomly chosen starting combinations, generate the list of combinations that have no more than max_common_spots in common
# # The starting node leading to the largest list will then be selected
# # In order to obtain the best possible ordering, repeat the process for decreasing number of common spots, until there is no overlap  
#  
# # initialise objects
# selected_combinations <- 1:nrow(all_combs)
# selected_combination_lists <- vector("list", max_common_spots+1) 
# 
# while(max_common_spots>=0){
#   print(paste("Finding combinations that have no more than",max_common_spots,"spots in common..."))
#   selected_combinations <- sort(subsample_combinations(edge_list,max_common_spots,nb_rand, selected_combinations))
#   selected_combination_lists[[max_common_spots+1]] <- selected_combinations
#   ##Now reduce edge list to only contain those combinations
#   edge_list <- edge_list[which(edge_list$comb_1%in%selected_combinations&edge_list$comb_2%in%selected_combinations),]
#   ## In the first iteration, save reduced edge list as it will be used in the next step
#   if (!exists("reduced_edge_list")){reduced_edge_list <- edge_list}
#   max_common_spots <- max_common_spots-1
# }
# 
# 
# ## 5. Sort the selected combinations from most different to most similar, and write it  
# 
# sorted_combinations <- sort_combinations(selected_combination_lists,reduced_edge_list)
# write.table(data.frame(all_combs[as.numeric(sorted_combinations$sorted_indices),],Mean_overlap=round(1000*as.numeric(sorted_combinations$mean_overlap))/1000,stringsAsFactors = F),file="Data/Paint_ID/Paint_IDs_rewritten.csv",col.names=T,row.names=F,quote=F,append=F)

```

```{r Floral_surveys}

# # checking which flowers I need samples for during fieldwork
# 
# # load in floral survey data
# survey <- read_csv('/Users/faith/Desktop/U Ottawa/PhD Chapter 3/sweat_bee_ecology/Data/Pollen_and_Surveys/Floral_surveys.csv')
# 
# # load in plant pollen sample data
# p_pollen_samples <- read_csv('/Users/faith/Desktop/U Ottawa/PhD Chapter 3/sweat_bee_ecology/Data/Pollen_and_Surveys/Pollen_samples_plant.csv')
# 
# 
# ## Make a list of pollen samples that I have
# 
# # organize by taxa alphabetically
# survey <- arrange(survey, Taxa)  
# 
# # make first letter capital
# survey$Taxa <- str_replace(survey$Taxa, "^\\w{1}", toupper)
# survey$Family <- str_replace(survey$Family, "^\\w{1}", toupper)
# p_pollen_samples$Taxa <- str_replace(p_pollen_samples$Taxa, "^\\w{1}", toupper)
# 
# # check the unique taxa, any diplucates from spelling erorrs? nothing jumpes out
# unique(survey$Taxa)
# # rename column
# survey <- survey %>% rename(Taxa_with_notes = Taxa)
# # take only first word (e.g., ignore "fruiting" or species names)
# survey <- mutate(survey, Taxa = word(Taxa_with_notes, 1))
# p_pollen_samples <- mutate(p_pollen_samples, Taxa = word(Taxa, 1))
# 
# # join data frames
# p_sample_list <- right_join(survey, p_pollen_samples)
# # organize by taxa alphabetically
# p_sample_list <- arrange(p_sample_list, Taxa)  
# 
# write_csv(p_sample_list, 'Data/Pollen_and_Surveys/Pollen_sample_list.csv')

```

```{r Bee_pollen_samples}

# how many bees did I mark?
IDs_JAM <- read_csv('Data/Paint_ID/Paint_IDs_JAM.csv')
IDs_KB <- read_csv('Data/Paint_ID/Paint_IDs_KB.csv')
length(unique(IDs_JAM$Bee_ID)) # 82 
length(unique(IDs_KB$Bee_ID)) # 32 
# 114 in total


## Pollen Count Dataframe

# after identifying the pollen blindly, now merge the pollen ID and the bee ID files together 
pollen_codes <- read_csv('Data/Pollen_and_Surveys/Pollen_codes.csv')
pollen_samples_ID <- read_csv('Data/Pollen_and_Surveys/Pollen_samples_ID.csv')
pollen <- full_join(pollen_samples_ID, pollen_codes, by = "Slide_code") # join

# reorder columns
pollen = pollen %>% select(Site, Bee_ID, Day, Month, Year, Slide_code, Family, Subtype, Count, Pollen_colour)

# creat date column
pollen$Date <- with(pollen, paste(Year, paste0(Month,sep = '-', Day), sep = '-'))
str(pollen)
pollen$Date <- as.Date(pollen$Date)

# combine ID with site in case the same ID was used for both sites
pollen$Bee_ID <- as.character(pollen$Bee_ID)
pollen$Bee_ID <- paste(pollen$Site, pollen$Bee_ID, sep = '_') 
table(pollen$Bee_ID) # looks good

# count number of samples for each bee
pollen <- pollen %>%
  group_by(Bee_ID) %>%
  mutate(Sample_counts = n_distinct(Date)) %>%
  ungroup()

# remove pollen types with less than 1% (1-2 pollen grains) because it could be from landing on the flower for nectar or contamination from making pollen slides, likely not a bee collecting pollen
pollen <- pollen %>% filter(Count > 3)


# descriptive
# 
# # what are the repeated samples like for pollen collection?
# Pollen_collection_JAM_repeats <- Pollen_collection_JAM %>% 
#   group_by(ID) %>% 
#   summarize(n = n()) %>% 
#   ungroup()
# Pollen_collection_KB_repeats <- Pollen_collection_KB %>% 
#   group_by(ID) %>% 
#   summarize(n = n()) %>% 
#   ungroup()
# table(Pollen_collection_JAM_repeats$n)
# table(Pollen_collection_KB_repeats$n)
# # 29 bees 1x, 12 bees 2x, 6 bees 3x, and 3 bees 4x


```

```{r Pollen_figure}


library(ggplot2)

# order by bee ID then filter to make 3 figures because too many individuals for just one
pollen %>% arrange(Date)

str(pollen)

# make date labels for the figure
pollen <- pollen %>%
  mutate(
    Date_label  = format(Date, "%b %d"),                    
    Date_label  = factor(Date_label, levels = format(sort(unique(Date)), "%b %d")))


pollen %>% 
  filter(Sample_counts > 1) %>% 
  ggplot(aes(x = Date_label, y = Count, fill = Family)) +
  geom_bar(stat = "identity", position = "fill") +  # 'fill' for proportions
  scale_y_continuous(labels = scales::percent) +
  labs(x = "Date", y = "Proportion of pollen types") +
  facet_wrap(~ Bee_ID, scales = "free_x") 


```

```{r Behaviour_data}

beehave_0 <- read_csv('Data/Behaviour/Video_logs_summary.csv')
str(beehave_0)

# creat date column
beehave_0$Date <- with(beehave_0, paste(Year, paste0(Month,sep = '-', Day), sep = '-'))
beehave_0$Date <- as.Date(beehave_0$Date)
# group by week
beehave_0$Week <- strftime(beehave_0$Date , format = "%V")

# Number of females
 # liberal : pollen collection, digging, vigilance, and leaving
 # moderate : pollen collection, digging and vigilance
 # conservative : pollen collection, digging and IF we know their ID, vigilance or leaving nest or entering without pollen
 # vigilance is peaking out of the nest if they do not leave for the following 2 minutes

# exceptions ###### incorperate into df
# J75: two bees painted from this nest

# make summary with only 1 row per nest
beehave_sum <- distinct(beehave_0, Nest, Num_females_con, Date, .keep_all= TRUE)
# remove columns that don't make sense for summary df
beehave_sum <- beehave_sum %>% 
  select(Nest, Site, Num_females_con, Num_females_mod, Num_females_lib, Date, Week)
# sometimes there are two rows per date and nest combo because we filmed the nest subsequently with a second camera (e.g., after the first one died or the SD card filled up)
# so if there are duplciate nest-date combos, remove the lowest valued Num_females_con
beehave_sum <- beehave_sum %>% 
  group_by(Nest, Date) %>% 
  slice_max(Num_females_con, n=1) %>% 
  ungroup

# descriptive
length(unique(beehave_sum$Nest)) # 51 nests observed 
#### count how many are solial or solitary, and compare with when males are leaving. Maybe a figure?


```
